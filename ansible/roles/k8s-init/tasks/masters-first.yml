- name: set k8s_cluster_token default
  set_fact:
    k8s_cluster_token: "9aeb42.99b7540a5833866a"
  run_once: true
  when: k8s_cluster_token is undefined

- name: generate the kubeadm 1.12 yaml configuration
  template:
    src: templates/k8s-kube-adm-12.j2
    dest: /root/kube-adm.yml
  when: k8s_version is search("1.12")

- name: generate the kubeadm 1.13 yaml configuration
  template:
    src: templates/k8s-kube-adm-13.j2
    dest: /root/kube-adm.yml
  when: k8s_version is search("1.13")

- name: generate the kubeadm 1.14 yaml configuration
  template:
    src: templates/k8s-kube-adm-14.j2
    dest: /root/kube-adm.yml
  when: k8s_version is search("1.14")

- name: generate the kubeadm 1.15 yaml configuration
  template:
    src: templates/k8s-kube-adm-15.j2
    dest: /root/kube-adm.yml
  when: k8s_version is search("1.15") 

- name: generate the kubeadm 1.16 yaml configuration
  template:
    src: templates/k8s-kube-adm-16.j2
    dest: /root/kube-adm.yml
  when: k8s_version is search("1.16")

- name: initialize cluster on first master (1.12) CentOS 
  shell: "kubeadm init --config kube-adm.yml > /tmp/kube-status"
  args:
    chdir: /root
  ignore_errors: false
  when: k8s_version is search("1.12") and cluster_type == 'centos-k8s' 

- name: initialize cluster on first master (1.12) Fedora and Ubuntu
  shell: "kubeadm init --config kube-adm.yml --ignore-preflight-errors=SystemVerification > /tmp/kube-status"
  args:
    chdir: /root
  ignore_errors: false
  when: k8s_version is search("1.12") and (cluster_type == 'fedora-k8s' or cluster_type == 'ubuntu-k8s')

- name: initialize cluster on first master (1.13) CentOS and Ubuntu
  shell: "kubeadm init --config kube-adm.yml > /tmp/kube-status"
  args:
    chdir: /root
  ignore_errors: false
  when: k8s_version is search("1.13") and (cluster_type == 'centos-k8s' or cluster_type == 'ubuntu-k8s')

- name: initialize cluster on first master (1.13) Fedora
  shell: "kubeadm init --config kube-adm.yml --ignore-preflight-errors=SystemVerification > /tmp/kube-status"
  args:
    chdir: /root
  ignore_errors: false
  when: k8s_version is search("1.13") and cluster_type == 'fedora-k8s'

- name: initialize cluster on first master (1.14)
  shell: "kubeadm init --config kube-adm.yml --experimental-upload-certs > /tmp/kube-status"
  args:
    chdir: /root
  ignore_errors: false
  when: k8s_version is search("1.14") 

- name: initialize cluster on first master (1.15+)
  shell: "kubeadm init --config kube-adm.yml --upload-certs > /tmp/kube-status"
  args:
    chdir: /root
  ignore_errors: false
  when: k8s_version is search("1.15") or k8s_version is search("1.16")

- name: register cluster status
  shell: "cat /tmp/kube-status"
  register: kubeadm_out

- name: kubeadm output
  debug: msg="{{ kubeadm_out.stdout_lines }}"

- name: get worker join command (pre 1.14)
  shell: "cat /tmp/kube-status | sed -n '/discovery-token-ca-cert-hash/,$p' "
  register: kubeadm_join_cmd
  when: k8s_version is search("1.12") or k8s_version is search("1.13")

- name: kubeadm worker join command
  debug: msg="{{ kubeadm_join_cmd.stdout }}"
  when: k8s_version is search("1.12") or k8s_version is search("1.13")

- name: export worker join command to /root/join_cmd
  shell: "echo '{{ kubeadm_join_cmd.stdout }} --ignore-preflight-errors=SystemVerification ' > /root/join_cmd "
  when: k8s_version is search("1.12") or k8s_version is search("1.13")

- name: create master_join_cmd
  shell: echo " --experimental-control-plane --ignore-preflight-errors=SystemVerification" | cat /root/join_cmd - | sed 's/\\n//g' | tr -d '\n' | xargs > /root/master_join_cmd
  args:
    chdir: /root
  ignore_errors: false
  register: master_join
  when: k8s_version is search("1.12") or k8s_version is search("1.13")

- name: list master join command
  shell: "cat /root/master_join_cmd "
  register: kubeadm_master_join_cmd
  when: k8s_version is search("1.12") or k8s_version is search("1.13") 

- name: kubeadm master join command
  debug: msg="{{ kubeadm_master_join_cmd.stdout }}"
  when: k8s_version is search("1.12") or k8s_version is search("1.13") 

- name: get master join command
  shell: "cat /tmp/kube-status | awk '/control-plane node/ {for(i=1; i<=5; i++) {getline; print}}' | tr -d '\n' | xargs "
  register: kubeadm_master_join_cmd
  when: k8s_version is not search("1.12") and k8s_version is not search("1.13")

- name: kubeadm master join command
  debug: msg="{{ kubeadm_master_join_cmd.stdout }}"
  when: k8s_version is not search("1.12") and k8s_version is not search("1.13")

- name: export master join command to /root/master_join_cmd
  shell: "echo '{{ kubeadm_master_join_cmd.stdout }}' > /root/master_join_cmd "
  when:  k8s_version is not search("1.12") and k8s_version is not search("1.13")  

- name: get worker join command
  shell: "cat /tmp/kube-status | awk '/worker node/{y=1;next}y' | tr -d '\n' |   sed 's/\\n//g' | xargs "
  register: kubeadm_join_cmd
  when:  k8s_version is not search("1.12") and k8s_version is not search("1.13")  

- name: kubeadm worker join command
  debug: msg="{{ kubeadm_join_cmd.stdout }}"
  when:  k8s_version is not search("1.12") and k8s_version is not search("1.13")  

- name: export worker join command to /root/join_cmd
  shell: "echo '{{ kubeadm_join_cmd.stdout }}' > /root/join_cmd "
  when:  k8s_version is not search("1.12") and k8s_version is not search("1.13")  

- name: setup kubectl configuration
  shell: rm -rf $HOME/.kube && mkdir -p $HOME/.kube && cp /etc/kubernetes/admin.conf $HOME/.kube/config && chown $(id -u):$(id -g) $HOME/.kube/config
  args:
    warn: false

- name: fetch the join_cmd file
  fetch:
    src: /root/join_cmd
    dest: "{{ playbook_dir | replace('/ansible', '') }}/clusters/{{ cluster_pkg_folder }}/"
    flat: yes     
  become: true   

- name: fetch the master_join_cmd file
  fetch:
    src: /root/master_join_cmd
    dest: "{{ playbook_dir | replace('/ansible', '') }}/clusters/{{ cluster_pkg_folder }}/"
    flat: yes     
  become: true   

- name: fetch the admin.conf file
  fetch:
    src: /etc/kubernetes/admin.conf
    dest: "{{ playbook_dir | replace('/ansible', '') }}/clusters/{{ cluster_pkg_folder }}/"
    flat: yes     
  become: true   

- name: fetch the kube-adm.yml from the first master
  fetch:
    src: /root/kube-adm.yml
    dest: "{{ playbook_dir | replace('/ansible', '') }}/clusters/{{ cluster_pkg_folder }}/"
    flat: yes     
  become: true   

- name: fetch the kube config from the first master
  fetch:
    src: /etc/kubernetes/admin.conf
    dest: "{{ playbook_dir | replace('/ansible', '') }}/clusters/{{ cluster_pkg_folder }}/kube-config"
    flat: yes     
  become: true   

- name: clean the existing PKI directory
  shell: "rm -rf {{ playbook_dir | replace('/ansible', '') }}/clusters/{{ cluster_pkg_folder }}/pki"
  args:
    warn: false
  ignore_errors: true 

- name: setup the PKI directory
  shell: "mkdir -p {{ playbook_dir | replace('/ansible', '') }}/clusters/{{ cluster_pkg_folder }}/pki"
  args:
    warn: false

- name: setup the PKI etcd directory
  shell: "mkdir -p {{ playbook_dir | replace('/ansible', '') }}/clusters/{{ cluster_pkg_folder }}/pki/etcd"
  args:
    warn: false

- name: fetch the PKI certs to the local {{ cluster_pkg_folder }}/pki
  fetch:
    src: /etc/kubernetes/pki/{{ item }}
    dest: "{{ playbook_dir | replace('/ansible', '') }}/clusters/{{ cluster_pkg_folder }}/pki/{{ item }}"
    flat: yes
  become: true   
  with_items:
    - ca.crt  
    - ca.key  
    - front-proxy-ca.crt  
    - front-proxy-ca.key  
    - sa.key
    - sa.pub
    - etcd/ca.crt  
    - etcd/ca.key  
#    - front-proxy-client.crt  
#    - front-proxy-client.key  
#    - apiserver.crt  
#    - apiserver-kubelet-client.crt  
#    - apiserver.key  
#    - apiserver-kubelet-client.key  
 
- name: setup Kubectl configuration on first master
  shell: kubectl get nodes
  register: nodes_out

- debug: msg="{{ nodes_out.stdout_lines }}"

#- name: Install Calico CNI
#  shell: kubectl apply -f https://docs.projectcalico.org/v3.1/getting-started/kubernetes/installation/hosted/kubeadm/1.7/calico.yaml
#  register: calico_out

#- debug: msg="{{ calico_out.stdout_lines }}"

- name: generate the master account
  template:
    src: templates/k8s-master-account.j2
    dest: /root/kube-master.yml

- name: install the master account
  shell: kubectl apply -f /root/kube-master.yml
  register: acct_out

- debug: msg="{{ acct_out.stdout_lines }}"

- name: generate the Web UI token
  shell: "kubectl -n kube-system describe secret $(kubectl -n kube-system get secret | grep admin-user | awk '{print $1}') | grep token: | sed 's/token:      //' > /root/web-ui-token"

- name: fetch the Web UI token to the local {{ cluster_pkg_folder }}
  fetch:
    src: /root/web-ui-token
    dest: "{{ playbook_dir | replace('/ansible', '') }}/clusters/{{ cluster_pkg_folder }}/"
    flat: yes     
  become: true   

- name: get master node status
  shell: kubectl get nodes
  register: master_node_out

- debug: msg="{{ master_node_out.stdout_lines }}"

- name: ensure the Kubelet is enabled
  shell: systemctl enable kubelet

